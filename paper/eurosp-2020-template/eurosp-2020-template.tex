\documentclass[compsoc,conference,a4paper,10pt,times]{IEEEtran}
% \IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{bmpsize}
\usepackage{xcolor}
\usepackage{lipsum}
\usepackage[colorlinks=true,urlcolor=black]{hyperref}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
\usepackage{minted}    

\usepackage[inline]{enumitem}
% New commands
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{defin}[theorem]{Definition}

\begin{document}

\title{Towards Certified Program Obfuscation}

\author{\IEEEauthorblockN{Weiyun Lu}
\IEEEauthorblockA{\textit{School of Electrical Engineering and Computer Science} \\
\textit{University of Ottawa}\\
Ottawa, Canada \\
WLU058@uottawa.ca}
\and
\IEEEauthorblockN{Bahman Sistany}
\IEEEauthorblockA{\textit{Cloakware Research} \\
\textit{Irdeto Canada}\\
Ottawa, Canada \\
bahman.sistany@irdeto.com}
\and
\IEEEauthorblockN{Amy Felty}
\IEEEauthorblockA{\textit{School of Electrical Engineering and Computer Science} \\
\textit{University of Ottawa}\\
Ottawa, Canada \\
afelty@uottawa.ca}
\and
\IEEEauthorblockN{Philip Scott}
\IEEEauthorblockA{\textit{School of Electrical Engineering and Computer Science} \\
\textit{University of Ottawa}\\
Ottawa, Canada \\
philip.scott@uottawa.ca}
}

\maketitle

\begin{abstract}
%We expect our systems including software systems to function ``correctly''. By ``correctly'', we mean that a system will behave according to explicit and/or implicit expectations. Typically, extensive testing is done to increase the confidence in correct functionality of a piece of software but positive test results are not a proof of correctness. In \emph{High Assurance} systems, formal verification based methods are used. Behaviour of interest such as functionality, safety and security may be expressed via some sort of formal specification language.

\par How can one perform code transformations such as obfuscating transformations or optimizing transformations on code that is assumed to be correct with respect to certain specified behaviour? Will the transformed code preserve the specified behaviour as one expects? 

\par To achieve the highest levels of assurance that the transformations have maintained correctness of the code, is to prove the two versions of the program (before and after the transformation) is equivalent. Total equivalency between the two versions of a program certainly implies the correctness of any specified properties of interest but what if we directly try to show validity of these properties on the transformed program? 

\par In this thesis, we lay the foundation to study and reason about code obfuscating transformations and show how the preservation of certain behaviours may be ``certified''. To this end, we apply techniques of formal specification and verification, by using the Coq Proof Assistant and IMP (a simple imperative language within it), to formulate what it means for a program's semantics to be preserved by an obfuscating transformation, and give formal machine-checked proofs that these properties hold. 

\par We describe our work on opaque predicates, a simple control flow obfuscation, and elements of control flow flattening transformation, a more complex control flow obfuscation.  Along the way, we employ Hoare logic as our foundational specification language, as well as augment the IMP language with Switch statements.  We also define a lower-level flowchart language to wrap around IMP for modelling certain flattening transformations, treating blocks of codes as objects in their own right.

\end{abstract}

\begin{IEEEkeywords}
obfuscation, verification, security, correctness, Coq, proof
\end{IEEEkeywords}

\section{Introduction}
\subsection{Background and Motivation}
We expect our systems including software systems to function ``correctly''. By ``correctly'', we mean that a system will behave according to explicit and/or implicit expectations or said another way to its written and/or unwritten specifications. Typically, extensive testing is done to increase the confidence in correct functionality of a piece of software but alas testing is known to be based on inductive reasoning where more tests passing can only increase the likelihood of correctness, so positive testing results are not a proof of correctness. In systems where more assurance of correctness is required various types of deductive reasoning is used. These are formal verification methods based on theoretical foundations rooted in logic. It is important to note that, formal verification transfers the problem of confidence in program correctness to the problem of confidence in specification correctness, so it is not a silver bullet however since specifications are often smaller and less complex to express, we have successfully reduced the trusted computing base (TCB) and increased our chances of achieving correctness.

Formal verification based methods, used to show a (software) system behaves as its specification says, typically employ a specification language based on the familiar ``assertions''. A specification is typically expressed in some variation of first order logic and the verification system will deductively try to prove the assertions correct or signal that they don't hold. This is a rather elaborate process where assertions (general propositional statements about program fragments that are expected to hold) are used to generate verification conditions (VC), logic formulas, that are then fed into a satisfiability modulo theories (SMT) solver, either behind the scenes in a verification backend or in more visible to the verification expert. VC generation for program verification goes back to at least Hoare's triples, Eiffel style contracts and proof-carrying-code (PCC) of Necula\cite{b7}.

How can one perform code transformations such as obfuscating transformations or optimizing transformations on code that is assumed to be correct with respect to certain specified behaviour (expressed in some assertion language) while preserving the correctness of the specified behaviour? 

To achieve the highest levels of assurance that the transformations have maintained correctness of the code, is to prove the two versions of the program (before and after the transformation) is equivalent. Proving equivalency is doable in certain cases but in general is still extremely hard to do for general programs. Despite the difficulty, there are now formally verified compilers such as CompCert. However, the problem with verifying realistic systems such as a compiler is scale. CompCert verification of semantic equivalence between C and generated assembly took several man years to complete. The cost of using formal verification for mere mortals (on realistic systems) is still high. 

Total equivalency between the two versions of a program certainly implies the correctness of any program properties of interest but what if we directly try to show validity of these properties? What if we limit ourselves to only proving properties of interest in the ``before'' version of a program are maintained in the ``after'' version of the program (after a transformation is applied)? 

Certain simple transformations simply don't invalidate expressed properties about the ``before'' version versus the ``after'' version. Below the program snippet in listing [\ref{lst:before}] asserts that $y > 2$ which we can verify visually to be true. In the snippet in listing [\ref{lst:after}] we use a simple obfuscating transformation called variable splitting where we have split the variable $x$ into two other variables $x1$ and $x2$ and we see that (visually) the assertion $y > 2$ still holds.


\begin{listing}
\caption{Original Code}
\label{lst:before}
\begin{minted}
[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize
] {c}
x = 2; y = 5;
y = x + y;
assert(y > 2);
\end{minted}
\end{listing}

\begin{listing}
\caption{Obfuscated Code}
\label{lst:after}
\begin{minted}
[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize
] {c}
x1 = 1; x2 = 1; y = 5;
y = x1 + y; y = x2 + y;
assert(y > 2);
\end{minted}
\end{listing}

In general, though, most transformations, whether optimizations or obfuscations but specially obfuscations, invalidate assertions that hold true about the ``before'' version. Obfuscation is especially troublesome because the goal of obfuscation is to hide the functionality of the code from prying eyes while maintaining the functionality of the ``before'' program. ``Prying eyes'' could as easily be the same as some kind of static analysis tool where an attacker is trying to determine certain facts about the code and obfuscation is trying to make this difficult. The program in listing [\ref{lst:beforeopaque}] is correct with respect to the assertion that is expressed (e.g. $z == 30$) as is evident by simple inspection of the code. The program snippet in listing [\ref{lst:afteropaque}] is the ``after'' program where a non-linear opaque predicate transformation has been applied to hide the fact that at program's end, value of $z$ is in fact 30. We can see that the transformation makes it a bit harder to see that the assertion still holds but knowing the fact that $\forall x \in \mathbb{Z}, ((x^2 + x)\bmod 2) == 0$ , we can deduce that the assertion does hold and the value of $z$ is in fact still 30. 

This paper describes steps towards implementing a framework in the Coq Proof Assistant and based on IMP\cite{SFV2}, a simple imperative language. to study obfuscating transformations, their impact on programs and how specified behaviour may be preserved beyond the transformations. A of number of initial goals and principles drove the direction of this research: 
\begin{enumerate*}
  \item Not reinventing the wheel: start out with IMP a familiar small imperative language implemented in Coq and use its accompanying formalized semantics in \cite{SFV2}.
  \item Accessibility to as wide an audience as possible: an obvious option was to use CompCert and Clight as \cite{Blazy2} have done. We would have started with lots of proofs and formalisms for free (already done by the CompCert team) however the significant learning curve associated with learning CompCert infrastructure seemed prohibitive. We deemed IMP and Coq much more accessible.\label{goal2}
  \item Extendibility of the framework: Following the lead of \cite{SFV2} where a number of extensions to IMP are easily added and studied, we wanted the ability to build our obfuscation infrastructure incrementally on top of IMP.\label{goal3}
  \end{enumerate*} 
  
Keeping these research goals in mind the contributions of this paper are the following:

\begin{itemize}
    \item We consider different formulations of what it means for a transformation to be semantics-preserving, including complete state equivalence as well as Hoare logic equivalence. In this particular setting, the latter is a novel approach, and we give examples of its use with opaque predicate transformations. In addition, use of Hoare logic in this context leads to establishing our main approach to ``certifying obfuscating transformations'': our obfuscating transformations will be ``decorated''  \`a la  Pierce's \cite{SFV2} with additional assertions and their proofs.\label{itm:1}
    \item We give clear and detailed explanations of the proofs and tactics in Coq, which, to the best of our knowledge, the existing literature does not, thus providing an accessible explanation of not just obfuscation techniques, but also in tandem with its formalization and verification inside Coq. This follows from research goal \ref{goal2}.\label{itm:2}
    \item We begin with a minimal imperative programming language inside Coq for reasoning about programs and their transformations, and then augment it as needed for control flow flattening algorithms, first by augmenting its syntax and semantics with switch statements, and then by defining a lower-level flowchart language that wraps around blocks of code in order to model real-world intermediate languages used in obfuscation tools. This follows our research goals \ref{goal2} and \ref{goal3}. \label{itm:3}
\end{itemize}


%This example is a good preview of a key part of our research, where we may have to supply additional facts to show that our transformations indeed maintain prior program properties expressed as specifications. The assertions will capture properties or conditions that need to hold true for the transformed code as evidence the transformations have not invalidated the specifications of the original code. Think of the assertions as a kind of a key that can undo the transformations to show that the desired behaviour (as encoded in the specifications) are still valid. For some of the more sophisticated transformations we will need to help the verification to discharge (i.e. to solve) our assertions. We will accomplish this by providing ``hints'' along with the corresponding assertions. In formal annotation language settings, assertions are specified using the familiar `assert' facility while the hints are expressed using the 'assume' facility. 
% Bahman: need to tie Hoare logic as a starting point to eventually having a small assertion language where we supply additional facts as `assume' statements. Of course this assertion language is part of our future work and not yet implemented.


%The idea is to accompany the transformations with invariants or assertions that will help the verification process discharging the transformed programsin some assertion language starting with using Hoare logic. The invariants will capture properties or conditions that need to hold true for the transformed code as evidence the transformations have not invalidated the specifications of the code. Think of the invariants as a kind of a key that can undo the transformations to show that the desired behaviour (as encoded in the specifications) are still valid. 

\begin{listing}
\caption{Original Code}
\label{lst:beforeopaque}
\begin{minted}
[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize
] {c}
int main (int argc, char *argv[])
{
  unsigned int x = 10;
  unsigned int y = 20;
  unsigned int z = 0;

  z = x + y;
  assert(z == 30);
  return 0;
}
\end{minted}
\end{listing}

\begin{listing}
\caption{Obfuscated Code}
\label{lst:afteropaque}
\begin{minted}
[
frame=single,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize
] {c}
int main (int argc, char *argv[])
{
  unsigned int x = 10;
  unsigned int y = 20;
  unsigned int z = 0;

  unsigned int a = ((unsigned int)argc);
  unsigned int w = a * a;

  w = a + w;
  w = w % 2;
  if (w == 0)
  {
    z = x + y;
  }
  else
  {
    z = y - x;
  }
  assert(z == 30);
  return 0;
}
\end{minted}
\end{listing}

\section{Background --- formal verification}\label{two}
In this chapter we provide necessary background information used for formal verification --- namely, the Coq proof assistant, the simple imperative language IMP defined inside Coq, and Hoare logic for reasoning about pre- and post-conditions of programs.
\subsection{The Coq proof assistant}

Coq \cite{Coq} is a formal proof management system, an implementation of the \emph{Calculus of (co)inductive constructions}, which provides a formal language in which one can write mathematical definitions, algorithms and theorems, and an environment for the development of machine-checked proofs.  It is implemented (mostly) in OCaml\footnote{See \href{https://www.ocaml.org}{https://www.ocaml.org}.} and (a little bit of) C.

\subsection{CompCert certified C compiler}
Something formally defined and proven in Coq leads to a high assurance of correctness --- one example of this is \emph{CompCert} \cite{CompCert} by Xavier Leroy's team, a formally verified compiler written in Coq for (a large subset) of C.  The upshot of CompCert being formally verified is that it will not cause \emph{miscompilation errors} --- that is, the executable code produced is proven to behave exactly as the semantics specified by the source program.

\section{Software Foundations --- the IMP language}
We now give the necessary definitions and theorems from Software Foundations \cite{SFV2}, an interactive textbook on the mathematical foundations of reliable software, which is actually entirely a Coq script.

\par We use the \emph{IMP} language defined within the Software Foundations Coq files for our code obfuscation formalisms.  IMP, which simply stands for imperative, is a bare-bones simple imperative language, like C stripped of all nonessential features.  This simplicity allows us to focus on the nuts and bolts of formally specifying and proving correct individual obfuscating transformations, emphasizing modularity.

\par Since IMP is written inside Coq, we can formally reason about not just individual programs, but entire classes of programs, and even the language itself.  We give the definitions, lemmas, and theorems necessary for our work, but will omit many details and proofs.  

\par IMP is built up piece by piece in \cite{SFV2} with multiple iterations (some failed, some tangential) for pedagogical purposes, but we will only present the final form that we end up using.  IMP has the basics of natural number arithmetic, booleans, and commands consisting of assignment, skip, if-then-else, and while-do-end.

\subsection{Command equivalence}\label{commequiv} 
    For two commands (IMP programs) $c_1$ and $c_2$ to be equivalent means that for any pair of states $st$ and $st'$, $c_1$ takes $st$ to $st'$ if and only if $c_2$ takes $st$ to $st'$.  In Coq,
\begin{verbatim}
Definition cequiv (c1 c2 : com) : Prop 
  := forall (st st' : state), 
(c1 / st \\ st') <-> (c2 / st \\ st').
\end{verbatim}


\subsection{Hoare logic}
\emph{Hoare logic} is a way for us to prove that executing a program will result in satisfying certain post-conditions, (possibly) conditional on certain pre-conditions being met.  This involves defining a natural way of writing program specifications, along with a compositional proof technique to prove correctness with respect to them.
\begin{defin}[Hoare triple]
	A \emph{Hoare triple}, which we sometimes refer to simply as a triple, consists of a pre-condition $P$, a program $c$, and a post-condition $Q$, written
    \[
    	(| P |)\ c\ (| Q |),
    \]
    which specifies that whenever $P$ is true before execution, running the program $c$ is guaranteed to make $Q$ true after execution.  This informal definition leaves states implicit, but for the formulation in Coq we will need to take states into account.
\end{defin}

\begin{defin}[Assertion]
An \emph{assertion} about a program's state, formally, is a function from states to propositions.
\begin{verbatim}   Definition Assertion := state -> Prop.\end{verbatim}
\par Informally, for some assertion $P$ and some state $st$, the proposition $P(st)$ represents the statement that $P$ holds in state $st$.  
As an example, let $st$ be the state where the value of every variable is 0.  Let $P$ be the assertion that $x=0$.  Then $P(st)$ is the proposition ``$x = 0$ in the state $st$".
\end{defin}

\section{Opaque predicates in IMP/Coq}

We now enter the main topic of the thesis proper, formalizing and certifying the opaque predicate transformation mentioned earlier. 

\subsection{Opaque predicate obfuscation}\label{subsec: opaquedefn}
	An \emph{opaque predicate} \cite{CoNa} is a predicate\footnote{This could be any statement in a program that could evaluate to true or false, but we will only be concerned with arithmetic formulas in this thesis.} that always evaluates to either \emph{true} or \emph{false} and the truth-value of which is known to the transformation but hard to deduce by an attacker \cite{Prada}. The code under the \emph{false} branch is never evaluated at runtime so \emph{opaque predicates} incur no runtime performance.

Of course, the absolutely most basic opaque predicates are just the boolean constants \emph{true} and \emph{false} themselves, but these are not very useful in practice because it is immediately obvious what is happening in the program, and neither the simplest of humans nor tools will be fooled. For a more advanced treatment of opaque predicates and how they may be broken see \cite{Prada}.


An  \emph{opaque predicate} transformation takes as inputs a program to be obfuscated, $c_1$, an opaque predicate $P$, and a dummy program\footnote{It's not known to an attacker, a priori, that it's a dummy program.  In practice, $c_2$ should be constructed so that it is not obvious; e.g.\ $c_2$ should not be simply an empty program, but should be complicated enough that it looks like it could feasibly be intended to be executed.} $c_2$, and returns the program
\begin{verbatim}
    IFB (P x) THEN c1 ELSE c2 FI.
\end{verbatim}

\par In the Section \ref{naive}, we describe our initial (straightforward, naive) attempt, explicitly defining the transformation to introduce the lines of code that assign variables associated with the opaque predicate (as one may naturally expect to write code in a typical imperative language), and see that trying to state a general theorem about command equivalence ends up being problematic.  
\par However, we then discuss how this spawned two ideas in different directions that rectify the issue.  On the one hand, we use Hoare logic with this first formulation, in Section \ref{hoarequiv}, to prove weaker conditions of a transformation than total command equivalence.  On the other hand, in Section \ref{noass} we reformulate the transformation to rely on values already existing in the state of the program, with the view that one may be applying an opaque predicate transformation to a small piece of code somewhere within a much larger program that would have such values floating around in the state already.
\par Finally in Section \ref{weakened}, we again employ Hoare logic to give a formal example of how an attacker who does not know about the opaque predicate's constant truth valuation, but otherwise can analyze (using static analysis) the program, ends up gaining weaker knowledge because of it.
\par All code for this chapter is in the file \verb$OBFS_opaque_predicate.v$ \cite{repo}.

\section{Command equivalence}\label{naive}
\subsection{Factorial program (countdown nonzero formulation)}\label{Fact}
    The following IMP program computes the factorial of a nonzero natural number.  The input is read from $X$, temporary values are stored as $Z$, and the factorial of the input is stored in $Y$ as the output.
\begin{verbatim}
Definition fact_nonzero : com :=
  Z ::= X;;
  Y ::= 1;;
  WHILE ! (Z <= 1) DO
    Y ::= Y * Z;;
    Z ::= Z - 1
  END.
\end{verbatim}

    The choice of factorial program as a candidate for examples of obfuscation is somewhat arbitrary.  It works well for illustrative purposes, however, as it is neither too complex nor completely trivial.

\subsection{Example}\label{firstoff}
    The $fact\_nonzero$ program with input $X=3$ yields output $Y=6$.  However, the story is not quite so simple (it is true that input $X=3$ yields $Y=6$, but as one can see in the Coq example, the state keeps track of the value of every variable involved in the program.).  The specification of this statement in Coq is
\begin{verbatim}
Example factorial_3: 
fact_nonzero / { X --> 3 } 
  { X --> 3; Z --> 3; Y --> 1; Y --> 3; 
  Z --> 2; Y --> 6; Z --> 1 }.
\end{verbatim}
    Note that formally, the final state holds the information of every intermediate assignment made by the program.  We can discern the output $Y=6$ by the fact that this is the rightmost case of a value being assigned to $Y$.  But wait, there's more!  We said earlier that in Coq, an example is no different from a proposition or a theorem in anything but name, so we must actually give a proof\footnote{This really is an example, to us.  But just because one declares ``here is an example of $X$" does not mean that $X$ is necessarily true.  In Coq, a proof must still be constructed.\par For example, in natural language, one can say ``An example of a prime number is 20051".  But this isn't immediately obvious, and one still needs to prove that example, for instance, by writing a program that tries to divide it by every number up to its square root.}.  Moreover, since command evaluation is relational and not functional (recall the reason for this is the possibility of non-terminating While loops), we must build the proof out step by step (see \cite{WeiRepo} for proofs).

For this section, we'll use as a simple opaque predicate namely,
    \[
    	\forall x.\ (x * x + x + x + 1) = (x + 1) * (x + 1).
    \]
We now define an opaque predicate transformation with our running example.  
    For the purposes of making the proofs easier to work with, and also to add a slight additional touch of obfuscation, we split up these assignments over multiple lines, as follows.
\begin{verbatim}
Definition opaque_trans x c1 c2 :=
  X' ::= (ANum x) ;;
  Z' ::= X' * X' ;;
  Z' ::= Z' + X' ;;
  Z' ::= Z' + X' ;;
  Z' ::= Z' + 1 ;;
  Z'' ::= X' + 1 ;;
  Z'' ::= Z'' * Z'' ;;
  IFB (BEq Z' Z'') THEN c1 ELSE c2 FI.
\end{verbatim}
holds and executes $c_2$ otherwise.  Of course, the above is true for all $x$, so the resulting program should be the same as $c_1$.  We'd like to claim that a program transformed by \verb$opaque_trans$ is equivalent to the original.

\par The observant logically inclined reader should, at this point, now be suspicious about taking this claim at face value.  What do we mean when we say the transformed program should be ``the same''?  The next example, which shows what happens when $opaque\_trans$ is applied to the $factorial\_3$ example, elucidates the necessity to be precise.  First, however, we will need a few lemmas that show our opaque predicate is indeed such, in various incarnations to be used in proofs.

\begin{lemma}\label{opaqueness}
    It is indeed the case that 
    \[ \forall x \in \mathbb{N}, 
	(x * x + x + x + 1) = (x + 1) * (x + 1).  \] 
\end{lemma}

\subsection{Example}\label{firstfact}
    For any $x\in \mathbb{N}$ and any program $c_2$, $opaque\_trans$ x $fact\_nonzero$ $c2$ with input $X=3$ yields output $Y=6$.  In Coq, however, it looks as follows.
    \begin{verbatim} Example factorial\_3\_opaque\_trans:
  forall x c2, 
  opaque_trans x fact_nonzero 
  c2 / { X --> 3 } 
    { X --> 3; X' --> x; Z' --> x * x; 
      Z' --> x * x + x; 
      Z' --> x * x + x + x;
      Z' --> x * x + x + x + 1; 
      Z'' --> x + 1; 
      Z'' --> (x + 1) * (x + 1); 
      Z --> 3; Y --> 1; Y --> 3; 
      Z --> 2; Y --> 6; Z --> 1 }.
    \end{verbatim}
      After instantiating variables and unfolding the definitions, the transformed program looks like:
      \begin{verbatim}
X' ::= x;;
Z' ::= X' * X';;
Z' ::= Z' + X';;
Z' ::= Z' + X';;
Z' ::= Z' + 1;;
Z'' ::= X' + 1;;
Z'' ::= Z'' * Z'';;
IFB Z' = Z''
THEN Z ::= X;;
  Y ::= 1;;
  WHILE ! (Z <= 1) DO Y ::= Y * Z;; 
      Z ::= Z - 1 
  END
ELSE c2 FI
      \end{verbatim}
      
%\par We cannot use $cequiv$ \eqref{commequiv} --- that is, we can't use it with the current formulation of the transformation) --- since new variables and assignments are introduced and kept track of in the definition of the state, even if we ultimately don't care about them.  
%\par Thus we were not ultimately successful, in this initial approach, in formulating a statement with command equivalence (\ref{commequiv}).  We'll revisit this in Section \ref{noass}.

\section{Related works}
There have been three papers, in all of which Sandrine Blazy (Universit\'{e} de Rennes 1) appears as a coauthor, that study code obfuscation in Coq.

\subsection*{Towards a formally verified obfuscating compiler}
\par \emph{Towards a formally verified obfuscating compiler} \cite{Blazy1} also uses IMP as the language for obfuscation, but studies data obfuscation techniques, as opposed to the control obfuscation techniques which opaque predicates and control flow flattening fall under \cite{CollbergTax}.
\par The first particular transformation studied herein is obfuscating integer constants, wherein all integer values are substituted by different ones in a distorted semantics using an obfuscating function $O: \mathbb{N} \to \mathbb{N}$.  The other discussed is variable encoding, which changes the names of variables.  A real-life application of this could be, for instance, to change a descriptive variable name like $account\_balance$ to a string of gibberish.
\par This is an inherently different class of techniques from the ones studied in the present work, and one can make a simple combinatorial argument that putting them together in the same obfuscation transformation would generate a synergistic effect on making a program more difficult to analyze.

\subsection*{Formal verification of control-flow graph flattening}
\par \emph{Formal verification of control-flow graph flattening} \cite{Blazy2} also studies control flow flattening, but the authors use the Clight language of CompCert (the formally verified C compiler in Coq, discussed in Chapter % Bahman: \ref{two}).  Should refer to a section: Background --- formal verification}\label{two}
Clight is the first intermediate language in the CompCert compiler, and the strategy used was to prove the correctness of the obfuscation strictly there, from which CompCert's own proofs of semantic preservation give the correctness of the rest of the compilation process ``for free".
\par On the one hand, this makes the work less elementary and less accessible, as it works with a nontrivial subset of the real C language, but on the other it is clear evidence that formal verification of obfuscation techniques need not be restricted to a small language like IMP (which would never be used in real software development), and other real-world practicalities considered in this paper include simulation techniques and analysis of running time.
\par This work also discusses some techniques for combining obfuscation techniques, such as splitting a switching variable into two different variables that are updated at different points of a program, as well as randomly encoding the values of the switch cases so that they are not just consecutive numbers beginning with 1.  These are necessary considerations, since we need to think one level higher about our attackers, and obfuscate the fact that we are obfuscating particular parts of our code with CFG flattening in the first place!
\par In comparing this work to ours, the present author believes there is merit both in the IMP and the CompCert routes.  In the former, the language used is of minimal complexity, which allows not only for specifications and proofs of transformations to be developed quicker without being bogged down in unnecessarily complicated features of the underlying language, but is also better suited for pedagogical purposes.  IMP is also Turing complete, so from a theoretical point of view there is no loss of generality in proofs made using it --- they can always be adapted to CompCert later.  But on the other hand, CompCert is, of course, closer to languages that would be of interest to real-world software development and so more practical in that sense.
\par The authors ran into a similar issue as in the present work of needing to separate switching variables from those in the program to be transformed, but their solution was different --- they instead use a function to parse the program to be transformed and generate a fresh variable which doesn't appear there to be used for the transformation.  From a practical point of view, this is perhaps more natural, and in line with how a real obfuscating tool would function --- generating new variables rather than demand that a certain specifically named variable doesn't exist in the source program.  Theoretically, though, these are equivalent, since any program can contain only finitely many variable names, and there are an infinite number to choose from.

\subsection*{Formal verification of a program obfuscation based on mixed boolean-arithmetic expressions}
\par \emph{Formal verification of a program obfuscation based on mixed boolean-arithmetic expressions} \cite{Blazy3} mixed boolean-arithmetic continues to work in Clight, which studies obfuscations that involve mixing arithmetic operators and bitwise boolean operators.  This is another data obfuscation which appears frequently in real-world binary code, but as it is based on features wildly beyond the capabilities of IMP, a detailed discussion is beyond the scope of the present work.



\begin{thebibliography}{00}
\bibitem{Blazy1} Sandrine Blazy and Roberto Giacobazzi. Towards a formally verified obfuscating compiler. In 2nd ACM SIGPLAN Software security and protection
workshop, SPP 2012, St. Petersburg, FL, USA, 2012. HAL (https://hal.archives-ouvertes.fr/).
\bibitem{Blazy2} Sandrine Blazy and Alix Trieu. Formal verification of control-fow graph flattening. In Proceedings of the 5th ACM SIGPLAN Conference on Certified
Programs and Proofs, CPP 2016, pages 176-187, New York, NY, USA, 2016. ACM.

\bibitem{Blazy3} Sandrine Blazy and Remi Hutin. Formal verification of a program obfuscation based on mixed boolean-arithmetic expressions. In Proceedings of the 8th ACM SIGPLAN International Conference on Certified Programs and Proofs, CPP 2019, Cascais, Portugal, January 14-15, 2019, pages 196-208, 2019.

\bibitem{CompCert} 	Xavier Leroy, ``Formal verification of a realistic compiler,'' Commun. ACM 52(7): 107-115 (2009)
\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
\bibitem{b7} George C. Necula: Proof-Carrying Code. POPL 1997: 106-119. 

% New items
\bibitem{WeiRepo} Weiyun Lu, ``GitHub repository to accompany the present thesis,'' \url{https://github.com/weiyunlu/coq-certified-obfuscation}, 2019 
\bibitem{CollbergTax} C. Collberg, C. Thomborson, and D. Low.
A Taxonomy of Obfuscating Transformations.
Technical Report 148, Department of Computer Science, University of Auckland, July 1997.
\bibitem{SFV2} Benjamin C. Pierce, Arthur Azevedo de Amorim, Chris Casinghino, Marco Gaboardi, Michael Greenberg, Cat?alin Hri?cu, Vilhelm Sjöberg, Andrew ?
Tolmach, and Brent Yorgey. Programming Language Foundations. Software Foundations series, volume 2. Electronic textbook, May 2018.
\bibitem{CoNa} 	Christian S. Collberg, Jasvir Nagra:
Surreptitious Software - Obfuscation, Watermarking, and Tamperproofing for Software Protection. Addison-Wesley Software Security Series, Addison-Wesley 2010, ISBN 978-0-321-54925-9, pp. I-XXVII, 1-748
\bibitem{Prada} Mila Dalla Preda, Matias Madou, Koen De Bosschere, Roberto Giacobazzi:
Opaque Predicates Detection by Abstract Interpretation. AMAST 2006: 81-95
\bibitem{Coq} "The {Coq Proof Assistant}", \url{https://coq.inria.fr}, 2019
\end{thebibliography}

\end{document}
